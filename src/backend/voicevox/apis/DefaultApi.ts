/* tslint:disable */
/* eslint-disable */
/**
 * VOICEVOX ENGINE
 * VOICEVOXの音声合成エンジンです。
 *
 * The version of the OpenAPI document: 0.7.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import {
    AccentPhrase,
    AccentPhraseFromJSON,
    AccentPhraseToJSON,
    AudioQuery,
    AudioQueryFromJSON,
    AudioQueryToJSON,
    HTTPValidationError,
    HTTPValidationErrorFromJSON,
    HTTPValidationErrorToJSON,
    ParseKanaBadRequest,
    ParseKanaBadRequestFromJSON,
    ParseKanaBadRequestToJSON,
    Speaker,
    SpeakerFromJSON,
    SpeakerToJSON,
} from '../models';

export interface AccentPhrasesAccentPhrasesPostRequest {
    text: string;
    speaker: number;
    isKana?: boolean;
}

export interface AudioQueryAudioQueryPostRequest {
    text: string;
    speaker: number;
}

export interface ConnectWavesConnectWavesPostRequest {
    requestBody: Array<string>;
}

export interface MoraDataMoraDataPostRequest {
    speaker: number;
    accentPhrase: Array<AccentPhrase>;
}

export interface MoraLengthMoraLengthPostRequest {
    speaker: number;
    accentPhrase: Array<AccentPhrase>;
}

export interface MoraPitchMoraPitchPostRequest {
    speaker: number;
    accentPhrase: Array<AccentPhrase>;
}

export interface MultiSynthesisMultiSynthesisPostRequest {
    speaker: number;
    audioQuery: Array<AudioQuery>;
}

export interface SynthesisSynthesisPostRequest {
    speaker: number;
    audioQuery: AudioQuery;
}

/**
 * 
 */
export class DefaultApi extends runtime.BaseAPI {

    /**
     * テキストからアクセント句を得ます。 is_kanaが`true`のとき、テキストは次のようなAquesTalkライクな記法に従う読み仮名として処理されます。デフォルトは`false`です。 * 全てのカナはカタカナで記述される * アクセント句は`/`または`、`で区切る。`、`で区切った場合に限り無音区間が挿入される。 * カナの手前に`_`を入れるとそのカナは無声化される * アクセント位置を`\'`で指定する。全てのアクセント句にはアクセント位置を1つ指定する必要がある。
     * テキストからアクセント句を得る
     */
    async accentPhrasesAccentPhrasesPostRaw(requestParameters: AccentPhrasesAccentPhrasesPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.text === null || requestParameters.text === undefined) {
            throw new runtime.RequiredError('text','Required parameter requestParameters.text was null or undefined when calling accentPhrasesAccentPhrasesPost.');
        }

        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling accentPhrasesAccentPhrasesPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.text !== undefined) {
            queryParameters['text'] = requestParameters.text;
        }

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.isKana !== undefined) {
            queryParameters['is_kana'] = requestParameters.isKana;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/accent_phrases`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * テキストからアクセント句を得ます。 is_kanaが`true`のとき、テキストは次のようなAquesTalkライクな記法に従う読み仮名として処理されます。デフォルトは`false`です。 * 全てのカナはカタカナで記述される * アクセント句は`/`または`、`で区切る。`、`で区切った場合に限り無音区間が挿入される。 * カナの手前に`_`を入れるとそのカナは無声化される * アクセント位置を`\'`で指定する。全てのアクセント句にはアクセント位置を1つ指定する必要がある。
     * テキストからアクセント句を得る
     */
    async accentPhrasesAccentPhrasesPost(requestParameters: AccentPhrasesAccentPhrasesPostRequest, initOverrides?: RequestInit): Promise<Array<AccentPhrase>> {
        const response = await this.accentPhrasesAccentPhrasesPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * クエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。各値の意味は`Schemas`を参照してください。
     * 音声合成用のクエリを作成する
     */
    async audioQueryAudioQueryPostRaw(requestParameters: AudioQueryAudioQueryPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<AudioQuery>> {
        if (requestParameters.text === null || requestParameters.text === undefined) {
            throw new runtime.RequiredError('text','Required parameter requestParameters.text was null or undefined when calling audioQueryAudioQueryPost.');
        }

        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling audioQueryAudioQueryPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.text !== undefined) {
            queryParameters['text'] = requestParameters.text;
        }

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/audio_query`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => AudioQueryFromJSON(jsonValue));
    }

    /**
     * クエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。各値の意味は`Schemas`を参照してください。
     * 音声合成用のクエリを作成する
     */
    async audioQueryAudioQueryPost(requestParameters: AudioQueryAudioQueryPostRequest, initOverrides?: RequestInit): Promise<AudioQuery> {
        const response = await this.audioQueryAudioQueryPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * base64エンコードされたwavデータを一纏めにし、wavファイルで返します。
     * base64エンコードされた複数のwavデータを一つに結合する
     */
    async connectWavesConnectWavesPostRaw(requestParameters: ConnectWavesConnectWavesPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.requestBody === null || requestParameters.requestBody === undefined) {
            throw new runtime.RequiredError('requestBody','Required parameter requestParameters.requestBody was null or undefined when calling connectWavesConnectWavesPost.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/connect_waves`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.requestBody,
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * base64エンコードされたwavデータを一纏めにし、wavファイルで返します。
     * base64エンコードされた複数のwavデータを一つに結合する
     */
    async connectWavesConnectWavesPost(requestParameters: ConnectWavesConnectWavesPostRequest, initOverrides?: RequestInit): Promise<Blob> {
        const response = await this.connectWavesConnectWavesPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * アクセント句から音高・音素長を得る
     */
    async moraDataMoraDataPostRaw(requestParameters: MoraDataMoraDataPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling moraDataMoraDataPost.');
        }

        if (requestParameters.accentPhrase === null || requestParameters.accentPhrase === undefined) {
            throw new runtime.RequiredError('accentPhrase','Required parameter requestParameters.accentPhrase was null or undefined when calling moraDataMoraDataPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/mora_data`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.accentPhrase.map(AccentPhraseToJSON),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * アクセント句から音高・音素長を得る
     */
    async moraDataMoraDataPost(requestParameters: MoraDataMoraDataPostRequest, initOverrides?: RequestInit): Promise<Array<AccentPhrase>> {
        const response = await this.moraDataMoraDataPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * アクセント句から音素長を得る
     */
    async moraLengthMoraLengthPostRaw(requestParameters: MoraLengthMoraLengthPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling moraLengthMoraLengthPost.');
        }

        if (requestParameters.accentPhrase === null || requestParameters.accentPhrase === undefined) {
            throw new runtime.RequiredError('accentPhrase','Required parameter requestParameters.accentPhrase was null or undefined when calling moraLengthMoraLengthPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/mora_length`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.accentPhrase.map(AccentPhraseToJSON),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * アクセント句から音素長を得る
     */
    async moraLengthMoraLengthPost(requestParameters: MoraLengthMoraLengthPostRequest, initOverrides?: RequestInit): Promise<Array<AccentPhrase>> {
        const response = await this.moraLengthMoraLengthPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * アクセント句から音高を得る
     */
    async moraPitchMoraPitchPostRaw(requestParameters: MoraPitchMoraPitchPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling moraPitchMoraPitchPost.');
        }

        if (requestParameters.accentPhrase === null || requestParameters.accentPhrase === undefined) {
            throw new runtime.RequiredError('accentPhrase','Required parameter requestParameters.accentPhrase was null or undefined when calling moraPitchMoraPitchPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/mora_pitch`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.accentPhrase.map(AccentPhraseToJSON),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * アクセント句から音高を得る
     */
    async moraPitchMoraPitchPost(requestParameters: MoraPitchMoraPitchPostRequest, initOverrides?: RequestInit): Promise<Array<AccentPhrase>> {
        const response = await this.moraPitchMoraPitchPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 複数まとめて音声合成する
     */
    async multiSynthesisMultiSynthesisPostRaw(requestParameters: MultiSynthesisMultiSynthesisPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling multiSynthesisMultiSynthesisPost.');
        }

        if (requestParameters.audioQuery === null || requestParameters.audioQuery === undefined) {
            throw new runtime.RequiredError('audioQuery','Required parameter requestParameters.audioQuery was null or undefined when calling multiSynthesisMultiSynthesisPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/multi_synthesis`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.audioQuery.map(AudioQueryToJSON),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * 複数まとめて音声合成する
     */
    async multiSynthesisMultiSynthesisPost(requestParameters: MultiSynthesisMultiSynthesisPostRequest, initOverrides?: RequestInit): Promise<Blob> {
        const response = await this.multiSynthesisMultiSynthesisPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Speakers
     */
    async speakersSpeakersGetRaw(initOverrides?: RequestInit): Promise<runtime.ApiResponse<Array<Speaker>>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/speakers`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(SpeakerFromJSON));
    }

    /**
     * Speakers
     */
    async speakersSpeakersGet(initOverrides?: RequestInit): Promise<Array<Speaker>> {
        const response = await this.speakersSpeakersGetRaw(initOverrides);
        return await response.value();
    }

    /**
     * 音声合成する
     */
    async synthesisSynthesisPostRaw(requestParameters: SynthesisSynthesisPostRequest, initOverrides?: RequestInit): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling synthesisSynthesisPost.');
        }

        if (requestParameters.audioQuery === null || requestParameters.audioQuery === undefined) {
            throw new runtime.RequiredError('audioQuery','Required parameter requestParameters.audioQuery was null or undefined when calling synthesisSynthesisPost.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/synthesis`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: AudioQueryToJSON(requestParameters.audioQuery),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * 音声合成する
     */
    async synthesisSynthesisPost(requestParameters: SynthesisSynthesisPostRequest, initOverrides?: RequestInit): Promise<Blob> {
        const response = await this.synthesisSynthesisPostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Version
     */
    async versionVersionGetRaw(initOverrides?: RequestInit): Promise<runtime.ApiResponse<any>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/version`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.TextApiResponse(response) as any;
    }

    /**
     * Version
     */
    async versionVersionGet(initOverrides?: RequestInit): Promise<any> {
        const response = await this.versionVersionGetRaw(initOverrides);
        return await response.value();
    }

}
